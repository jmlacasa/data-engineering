{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSource:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "\n",
    "    def fetch_data(self, ticker, interval, start_time=None, end_time=None):\n",
    "        raise NotImplementedError(\"Subclasses should implement this method\")\n",
    "\n",
    "\n",
    "class YFinanceSource(DataSource):\n",
    "    def fetch_data(self, ticker, interval=\"5m\", start_time=None, end_time=None):\n",
    "        # Now, we directly use the client (which is yfinance in this case)\n",
    "        data = self.client.download(ticker, interval=interval, start=start_time, end=end_time)\n",
    "        return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONNECT REDSHIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Redshift successfully!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "with open(\"pwd_redshift.txt\",'r') as f:\n",
    "    pwd= f.read()\n",
    "\n",
    "connection_params = dict(\n",
    "        host='data-engineer-cluster.cyhh5bfevlmn.us-east-1.redshift.amazonaws.com'\n",
    "        , dbname='data-engineer-database'\n",
    "        , user='juanmlacasa_coderhouse'\n",
    "        , password=pwd\n",
    "        , port='5439'\n",
    ")\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        **connection_params\n",
    "    )\n",
    "    print(\"Connected to Redshift successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Unable to connect to Redshift.\")\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "                Open      High       Low     Close  Adj Close     Volume\n",
      "Date                                                                    \n",
      "1980-12-12  0.128348  0.128906  0.128348  0.128348   0.099449  469033600\n",
      "1980-12-15  0.122210  0.122210  0.121652  0.121652   0.094261  175884800\n",
      "1980-12-16  0.113281  0.113281  0.112723  0.112723   0.087343  105728000\n",
      "1980-12-17  0.115513  0.116071  0.115513  0.115513   0.089504   86441600\n",
      "1980-12-18  0.118862  0.119420  0.118862  0.118862   0.092099   73449600\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Create an instance of YFinanceSource, passing the yfinance module as the client\n",
    "yfinance_source = YFinanceSource(client=yf)\n",
    "\n",
    "# Fetch data for Apple Inc. with a daily interval\n",
    "data = yfinance_source.fetch_data(ticker=\"AAPL\", interval=\"1d\")\n",
    "\n",
    "# Display the data\n",
    "print(data.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_record(conn, search_value, table_name, entity):\n",
    "    # Check if data source exists\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"\"\"\n",
    "            SELECT {entity}_id FROM {table_name} WHERE {entity}_name = '{search_value}';\n",
    "            \"\"\")\n",
    "        try:\n",
    "            record_id = cur.fetchone()[0]\n",
    "        except TypeError:\n",
    "            record_id = None\n",
    "    if not record_id:\n",
    "        # Insert new data source\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(f\"\"\"\n",
    "                INSERT INTO {table_name} ({entity}_name) VALUES ('{search_value}');\n",
    "            \"\"\")\n",
    "            cur.execute(f\"\"\"\n",
    "                SELECT MAX({entity}_id) FROM {table_name}\n",
    "            \"\"\")\n",
    "            record_id = cur.fetchone()[0]\n",
    "    return record_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 1\n"
     ]
    }
   ],
   "source": [
    "asset_id = get_or_create_record(conn, \"AAPL\", \"assets\", \"asset\")\n",
    "source_type_id = get_or_create_record(conn, \"Platform\", \"source_types\", \"type\")\n",
    "data_source_id = get_or_create_record(conn, \"Yahoo Finance\", \"data_sources\", \"source\")\n",
    "print(asset_id, source_type_id, data_source_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)\n",
    "data.columns = [c.lower().replace(' ', '_') for c in data.columns]\n",
    "data.rename(columns={'date':'timestamp'}, inplace=True)\n",
    "data['asset_id'] = asset_id\n",
    "data['source_id'] = data_source_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INSERT INTO ohlcv_data (\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"adj_close\", \"volume\", \"asset_id\", \"source_id\") VALUES %s'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from psycopg2.extras import execute_values\n",
    "\n",
    "def load_redshift(conn, table_name, dataframe):\n",
    "    with conn.cursor() as curs:\n",
    "        values = [tuple(x) for x in dataframe.to_numpy()]\n",
    "        cols = '\"'+'''\", \"'''.join(data.columns)+'\"'\n",
    "        # define INSERT INTO statement\n",
    "        insert_sql = f\"INSERT INTO {table_name} ({cols}) VALUES %s\"\n",
    "        # Execute the transaction to insert the data\n",
    "        curs.execute(\"BEGIN\")\n",
    "        execute_values(curs, insert_sql, values)\n",
    "        curs.execute(\"COMMIT\")\n",
    "    print('Proceso terminado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as curs:\n",
    "    curs.execute(\"ROLLBACK\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso terminado\n"
     ]
    }
   ],
   "source": [
    "load_redshift(conn, 'ohlcv_data', data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coder-de",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a0f6c032de7be79d5c7f13f397ddb255c643e6cfe5a1086054ff4a4b4b03150"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
