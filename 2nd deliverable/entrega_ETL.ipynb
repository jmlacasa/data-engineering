{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONNECT to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Redshift successfully!\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "\n",
    "# dotenv.load_dotenv(fr\"{home}\\creds\\local_postgres.txt\")\n",
    "# schema = 'deliverable_2'\n",
    "dotenv.load_dotenv(fr\"{home}\\creds\\pwd_redshift.txt\")\n",
    "schema = 'juanmlacasa_coderhouse'\n",
    "\n",
    "connection_params = dict(\n",
    "        host=os.getenv('host')\n",
    "        , dbname=os.getenv('dbname')\n",
    "        , user=os.getenv('user')\n",
    "        , password=os.getenv('password')\n",
    "        , port=os.getenv('port')\n",
    ")\n",
    "\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        **connection_params\n",
    "    )\n",
    "    print(\"Connected to Redshift successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Unable to connect to Redshift.\")\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the parameters for the data to be fetched\n",
    "ticker_info = dict(ticker_symbol = 'AAPL'\n",
    "                   , data_source='Yahoo Finance'\n",
    "                   , source_type = 'Platform'\n",
    "                   , interval='1d'\n",
    "                   , start_date = '2023-01-01'\n",
    "                   , end_date = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>130.279999</td>\n",
       "      <td>130.899994</td>\n",
       "      <td>124.169998</td>\n",
       "      <td>125.070000</td>\n",
       "      <td>124.538658</td>\n",
       "      <td>112117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>126.889999</td>\n",
       "      <td>128.660004</td>\n",
       "      <td>125.080002</td>\n",
       "      <td>126.360001</td>\n",
       "      <td>125.823189</td>\n",
       "      <td>89113600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>127.129997</td>\n",
       "      <td>127.769997</td>\n",
       "      <td>124.760002</td>\n",
       "      <td>125.019997</td>\n",
       "      <td>124.488869</td>\n",
       "      <td>80962700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-06</th>\n",
       "      <td>126.010002</td>\n",
       "      <td>130.289993</td>\n",
       "      <td>124.889999</td>\n",
       "      <td>129.619995</td>\n",
       "      <td>129.069336</td>\n",
       "      <td>87754700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-09</th>\n",
       "      <td>130.470001</td>\n",
       "      <td>133.410004</td>\n",
       "      <td>129.889999</td>\n",
       "      <td>130.149994</td>\n",
       "      <td>129.597076</td>\n",
       "      <td>70790800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2023-01-03  130.279999  130.899994  124.169998  125.070000  124.538658   \n",
       "2023-01-04  126.889999  128.660004  125.080002  126.360001  125.823189   \n",
       "2023-01-05  127.129997  127.769997  124.760002  125.019997  124.488869   \n",
       "2023-01-06  126.010002  130.289993  124.889999  129.619995  129.069336   \n",
       "2023-01-09  130.470001  133.410004  129.889999  130.149994  129.597076   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2023-01-03  112117500  \n",
       "2023-01-04   89113600  \n",
       "2023-01-05   80962700  \n",
       "2023-01-06   87754700  \n",
       "2023-01-09   70790800  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Fetch data for Apple Inc. with a daily interval\n",
    "data = yf.download(ticker_info['ticker_symbol']\n",
    "                   , interval=ticker_info['interval']\n",
    "                   , start=ticker_info['start_date']\n",
    "                   , end=ticker_info['end_date'])\n",
    "\n",
    "# Display the data\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_record(conn, search_value, table_name, entity):\n",
    "    ''''\n",
    "    This function ensures that a record with a specific search value exists in the database.\n",
    "    If the record already exists, it returns its ID.\n",
    "    If the record does not exist, it creates one and then returns the new ID.\n",
    "    '''\n",
    "\n",
    "    # --- Search for Existing Record ---\n",
    "    with conn.cursor() as cur:\n",
    "        # Construct and execute a SELECT query to search for an existing record\n",
    "        cur.execute(f\"SELECT {entity}_id FROM {schema}.{table_name} WHERE {entity}_name = '{search_value}';\")\n",
    "        try:\n",
    "            # If a record is found, retrieve its ID\n",
    "            record_id = cur.fetchone()[0]\n",
    "        except TypeError:\n",
    "            # If no record is found, set record_id to None\n",
    "            record_id = None\n",
    "\n",
    "    # --- Insert Record if Not Found ---\n",
    "    if not record_id:\n",
    "        with conn.cursor() as cur:\n",
    "            # Construct and execute an INSERT query to create a new record\n",
    "            cur.execute(f\"INSERT INTO {schema}.{table_name} ({entity}_name) VALUES ('{search_value}');\")\n",
    "            # Retrieve the ID of the newly created record\n",
    "            cur.execute(f\"SELECT {entity}_id FROM {schema}.{table_name} WHERE {entity}_name = '{search_value}';\")\n",
    "            record_id = cur.fetchone()[0]\n",
    "            # Commit the transaction to save the new record in the database\n",
    "            conn.commit()\n",
    "\n",
    "    # --- Return the Record ID ---\n",
    "    return record_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 2 3\n"
     ]
    }
   ],
   "source": [
    "asset_id = get_or_create_record(conn, ticker_info['ticker_symbol'], \"assets\", \"asset\")\n",
    "data_source_id = get_or_create_record(conn, ticker_info['data_source'], \"data_sources\", \"source\")\n",
    "source_type_id = get_or_create_record(conn, ticker_info['source_type'], \"source_types\", \"type\")\n",
    "print(asset_id, source_type_id, data_source_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)\n",
    "data.columns = [c.lower().replace(' ', '_') for c in data.columns]\n",
    "data.rename(columns={'date':'ts'}, inplace=True)\n",
    "data['asset_id'] = asset_id\n",
    "data['source_id'] = data_source_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extras import execute_values\n",
    "\n",
    "def load_redshift(conn, table_name, dataframe):\n",
    "    '''\n",
    "    This function loads data from a Pandas DataFrame into a specified table in a PostgreSQL database.\n",
    "    If records with the same primary key exist, the function updates them with the new values.\n",
    "    '''\n",
    "\n",
    "    # --- Convert DataFrame to List of Tuples ---\n",
    "    # Convert each row of the DataFrame into a tuple and create a list of these tuples\n",
    "    values = [tuple(x) for x in dataframe.to_numpy()]\n",
    "\n",
    "    # --- Format Column Names ---\n",
    "    # Construct a string of column names separated by commas\n",
    "    cols = '\"'+'''\", \"'''.join(dataframe.columns)+'\"'\n",
    "\n",
    "    # --- Prepare SQL Queries ---\n",
    "    # Construct the base INSERT INTO query and append the ON CONFLICT clause\n",
    "    insert_sql = f\"INSERT INTO {schema}.{table_name} ({cols}) VALUES %s\"\n",
    "    on_conflict_sql = f\"\"\"\n",
    "        ON CONFLICT (asset_id, source_id, ts)\n",
    "        DO UPDATE SET\n",
    "            (open, high, low, close, adj_close, volume) = \n",
    "            (EXCLUDED.open, EXCLUDED.high, EXCLUDED.low, EXCLUDED.close, EXCLUDED.adj_close, EXCLUDED.volume)\n",
    "    \"\"\"\n",
    "    insert_sql = insert_sql + on_conflict_sql\n",
    "\n",
    "    # --- Execute Transaction ---\n",
    "    # Execute the query using execute_values for batch insertion\n",
    "    with conn.cursor() as curs:\n",
    "        execute_values(curs, insert_sql, values)\n",
    "        conn.commit()\n",
    "\n",
    "    print('Proceso terminado')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "syntax error at or near \"ON\"\nLINE 2:         ON CONFLICT (asset_id, source_id, ts)\n                ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m load_redshift(conn, \u001b[39m'\u001b[39;49m\u001b[39mohlcv_data\u001b[39;49m\u001b[39m'\u001b[39;49m, data)\n",
      "Cell \u001b[1;32mIn[13], line 31\u001b[0m, in \u001b[0;36mload_redshift\u001b[1;34m(conn, table_name, dataframe)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39m# --- Execute Transaction ---\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m# Execute the query using execute_values for batch insertion\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39mwith\u001b[39;00m conn\u001b[39m.\u001b[39mcursor() \u001b[39mas\u001b[39;00m curs:\n\u001b[1;32m---> 31\u001b[0m     execute_values(curs, insert_sql, values)\n\u001b[0;32m     32\u001b[0m     conn\u001b[39m.\u001b[39mcommit()\n\u001b[0;32m     34\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProceso terminado\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\juanm\\anaconda3\\envs\\coder-de\\Lib\\site-packages\\psycopg2\\extras.py:1299\u001b[0m, in \u001b[0;36mexecute_values\u001b[1;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[0;32m   1297\u001b[0m     parts\u001b[39m.\u001b[39mappend(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1298\u001b[0m parts[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:] \u001b[39m=\u001b[39m post\n\u001b[1;32m-> 1299\u001b[0m cur\u001b[39m.\u001b[39;49mexecute(\u001b[39mb\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(parts))\n\u001b[0;32m   1300\u001b[0m \u001b[39mif\u001b[39;00m fetch:\n\u001b[0;32m   1301\u001b[0m     result\u001b[39m.\u001b[39mextend(cur\u001b[39m.\u001b[39mfetchall())\n",
      "\u001b[1;31mSyntaxError\u001b[0m: syntax error at or near \"ON\"\nLINE 2:         ON CONFLICT (asset_id, source_id, ts)\n                ^\n"
     ]
    }
   ],
   "source": [
    "load_redshift(conn, 'ohlcv_data', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close redshift connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as curs:\n",
    "    curs.execute(\"ROLLBACK\")\n",
    "    conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coder-de",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a0f6c032de7be79d5c7f13f397ddb255c643e6cfe5a1086054ff4a4b4b03150"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
