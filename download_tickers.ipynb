{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSource:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "\n",
    "    def fetch_data(self, ticker, interval, start_time=None, end_time=None):\n",
    "        raise NotImplementedError(\"Subclasses should implement this method\")\n",
    "\n",
    "\n",
    "class YFinanceSource(DataSource):\n",
    "    def fetch_data(self, ticker, interval=\"5m\", start_time=None, end_time=None):\n",
    "        # Now, we directly use the client (which is yfinance in this case)\n",
    "        data = self.client.download(ticker, interval=interval, start=start_time, end=end_time)\n",
    "        return data\n",
    "\n",
    "# methods to check if I have all the data\n",
    "# if I have the expected number of rows\n",
    "# if I have the expected number of columns\n",
    "# if I have the expected columns from the API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "                  Open        High         Low       Close  Adj Close  Volume\n",
      "Date                                                                         \n",
      "2010-09-09  102.500000  102.500000  101.139999  101.320000  79.068352   26500\n",
      "2010-09-10  101.680000  101.860001  101.300003  101.779999  79.427299    8600\n",
      "2010-09-13  102.959999  103.139999  102.500000  103.059998  80.426216   33750\n",
      "2010-09-14  102.839996  103.480003  102.379997  103.040001  80.410591   59400\n",
      "2010-09-15  102.620003  103.379997  102.400002  103.300003  80.613510    9250\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Create an instance of YFinanceSource, passing the yfinance module as the client\n",
    "yfinance_source = YFinanceSource(client=yf)\n",
    "\n",
    "# Fetch data for Apple Inc. with a daily interval\n",
    "apple_data = yfinance_source.fetch_data(ticker=\"VOO\", interval=\"1d\")\n",
    "\n",
    "# Display the data\n",
    "print(apple_data.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLoader:\n",
    "    def __init__(self, connection_params):\n",
    "        self.connection_params = connection_params\n",
    "\n",
    "    def load_data(self, data):\n",
    "        \"\"\"Load the provided data into the destination.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement this method\")\n",
    "\n",
    "import psycopg2\n",
    "class RedshiftLoader(BaseLoader):\n",
    "    def load_data(self, data):\n",
    "        \"\"\"Load data into Amazon Redshift.\"\"\"\n",
    "        with psycopg2.connect(**self.connection_params) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                # Similar to the SQLLoader but might have Redshift-specific optimizations\n",
    "                pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Redshift successfully!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "with open(\"pwd_redshift.txt\",'r') as f:\n",
    "    pwd= f.read()\n",
    "\n",
    "connection_params = dict(\n",
    "        host='data-engineer-cluster.cyhh5bfevlmn.us-east-1.redshift.amazonaws.com'\n",
    "        , dbname='data-engineer-database'\n",
    "        , user='juanmlacasa_coderhouse'\n",
    "        , password=pwd\n",
    "        , port='5439'\n",
    ")\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        **connection_params\n",
    "    )\n",
    "    print(\"Connected to Redshift successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Unable to connect to Redshift.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extras import execute_values\n",
    "\n",
    "def load_redshift(conn, table_name, dataframe):\n",
    "    dtypes= dataframe.dtypes\n",
    "    cols= list(dtypes.index )\n",
    "    tipos= list(dtypes.values)\n",
    "    type_map = {'int64': 'INT','int32': 'INT','float64': 'FLOAT','object': 'VARCHAR(50)','bool':'BOOLEAN'}\n",
    "    sql_dtypes = [type_map[str(dtype)] for dtype in tipos]\n",
    "    # Define variable SQL data_types\n",
    "    column_defs = [f\"{name} {data_type}\" for name, data_type in zip(cols, sql_dtypes)]\n",
    "    # Combine column definitions into the CREATE TABLE statement\n",
    "    table_schema = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            {', '.join(column_defs)}\n",
    "        );\n",
    "        \"\"\"\n",
    "    # Create table_schema\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(table_schema)\n",
    "    # generate schema values\n",
    "    values = [tuple(x) for x in dataframe.to_numpy()]\n",
    "    # define INSERT INTO statement\n",
    "    insert_sql = f\"INSERT INTO {table_name} ({', '.join(cols)}) VALUES %s\"\n",
    "    # Execute the transaction to insert the data\n",
    "    cur.execute(\"BEGIN\")\n",
    "    execute_values(cur, insert_sql, values)\n",
    "    cur.execute(\"COMMIT\")\n",
    "    print('Proceso terminado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cargar_en_redshift(conn=conn, table_name='interest_over_time', dataframe=iot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coder-de",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a0f6c032de7be79d5c7f13f397ddb255c643e6cfe5a1086054ff4a4b4b03150"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
