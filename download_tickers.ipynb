{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSource:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.column_mapping = None\n",
    "        self.data = None\n",
    "        self.ticker_info = dict(ticker_symbol = None\n",
    "                   , interval=None\n",
    "                   , start_date = None\n",
    "                   , end_date = None)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"DataSource({self.client}), {self.ticker_info}\"\n",
    "    \n",
    "    def fetch_data(self, ticker, interval, start_time=None, end_time=None):\n",
    "        raise NotImplementedError(\"Subclasses should implement this method\")\n",
    "    \n",
    "\n",
    "    def transform_data(self):\n",
    "        raise NotImplementedError(\"Subclasses should implement the 'transform_data' method\")\n",
    "    \n",
    "\n",
    "    def validate_data(self):\n",
    "        raise NotImplementedError(\"Subclasses should implement the 'validate_data' method\")\n",
    "    \n",
    "\n",
    "    def pipeline(self, ticker, interval, start_time=None, end_time=None):\n",
    "        self.ticker_info['ticker_symbol'] = ticker\n",
    "        self.ticker_info['interval'] = interval\n",
    "        self.ticker_info['start_date'] = start_time\n",
    "        self.ticker_info['end_date'] = end_time\n",
    "        self.fetch_data(ticker, interval, start_time, end_time)\n",
    "        self.transform_data()\n",
    "        self.validate_data()\n",
    "        return self.data\n",
    "\n",
    "\n",
    "class YFinanceSource(DataSource):\n",
    "    def __init__(self):\n",
    "        import yfinance as yf\n",
    "        super().__init__(yf)\n",
    "        self.column_mapping = {\n",
    "            'Date': 'ts',\n",
    "            'Open': 'open',\n",
    "            'High': 'high',\n",
    "            'Low': 'low',\n",
    "            'Close': 'close',\n",
    "            'Adj Close': 'adj_close',\n",
    "            'Volume': 'volume'\n",
    "        }\n",
    "    \n",
    "    def fetch_data(self, ticker, interval=\"5m\", start_time=None, end_time=None):\n",
    "        # Now, we directly use the client (which is yfinance in this case)\n",
    "        self.ticker_info['ticker_symbol'] = ticker\n",
    "        self.ticker_info['interval'] = interval\n",
    "        self.ticker_info['start_date'] = start_time\n",
    "        self.ticker_info['end_date'] = end_time\n",
    "\n",
    "        self.data = self.client.download(ticker, interval=interval, start=start_time, end=end_time)\n",
    "        return self.data\n",
    "    \n",
    "    def transform_data(self):\n",
    "        self.data = self.data.reset_index()\n",
    "        self.data = self.data.rename(columns=self.column_mapping)\n",
    "        return self.data\n",
    "    \n",
    "    def validate_data(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# methods to check if I have all the data\n",
    "# if I have the expected number of rows\n",
    "# if I have the expected number of columns\n",
    "# if I have the expected columns from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSource(<module 'yfinance' from 'c:\\\\Users\\\\juanm\\\\anaconda3\\\\envs\\\\coder-de\\\\Lib\\\\site-packages\\\\yfinance\\\\__init__.py'>), {'ticker_symbol': None, 'interval': None, 'start_date': None, 'end_date': None}\n"
     ]
    }
   ],
   "source": [
    "yfin = YFinanceSource()\n",
    "print(yfin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>133.520004</td>\n",
       "      <td>133.610001</td>\n",
       "      <td>126.760002</td>\n",
       "      <td>129.410004</td>\n",
       "      <td>127.331688</td>\n",
       "      <td>143301900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>128.889999</td>\n",
       "      <td>131.740005</td>\n",
       "      <td>128.429993</td>\n",
       "      <td>131.009995</td>\n",
       "      <td>128.905975</td>\n",
       "      <td>97664900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>127.720001</td>\n",
       "      <td>131.050003</td>\n",
       "      <td>126.379997</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>124.566811</td>\n",
       "      <td>155088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>128.360001</td>\n",
       "      <td>131.630005</td>\n",
       "      <td>127.860001</td>\n",
       "      <td>130.919998</td>\n",
       "      <td>128.817429</td>\n",
       "      <td>109578200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>132.429993</td>\n",
       "      <td>132.630005</td>\n",
       "      <td>130.229996</td>\n",
       "      <td>132.050003</td>\n",
       "      <td>129.929291</td>\n",
       "      <td>105158200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-01-11</td>\n",
       "      <td>129.190002</td>\n",
       "      <td>130.169998</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>128.979996</td>\n",
       "      <td>126.908577</td>\n",
       "      <td>100384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>129.690002</td>\n",
       "      <td>126.860001</td>\n",
       "      <td>128.800003</td>\n",
       "      <td>126.731491</td>\n",
       "      <td>91951100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>128.759995</td>\n",
       "      <td>131.449997</td>\n",
       "      <td>128.490005</td>\n",
       "      <td>130.889999</td>\n",
       "      <td>128.787903</td>\n",
       "      <td>88636800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-01-14</td>\n",
       "      <td>130.800003</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>128.759995</td>\n",
       "      <td>128.910004</td>\n",
       "      <td>126.839722</td>\n",
       "      <td>90221800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>128.779999</td>\n",
       "      <td>130.220001</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.139999</td>\n",
       "      <td>125.098160</td>\n",
       "      <td>111598500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-01-19</td>\n",
       "      <td>127.779999</td>\n",
       "      <td>128.710007</td>\n",
       "      <td>126.940002</td>\n",
       "      <td>127.830002</td>\n",
       "      <td>125.777069</td>\n",
       "      <td>90757300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>128.660004</td>\n",
       "      <td>132.490005</td>\n",
       "      <td>128.550003</td>\n",
       "      <td>132.029999</td>\n",
       "      <td>129.909607</td>\n",
       "      <td>104319500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>133.800003</td>\n",
       "      <td>139.669998</td>\n",
       "      <td>133.589996</td>\n",
       "      <td>136.869995</td>\n",
       "      <td>134.671875</td>\n",
       "      <td>120150900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>136.279999</td>\n",
       "      <td>139.850006</td>\n",
       "      <td>135.020004</td>\n",
       "      <td>139.070007</td>\n",
       "      <td>136.836594</td>\n",
       "      <td>114459400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-01-25</td>\n",
       "      <td>143.070007</td>\n",
       "      <td>145.089996</td>\n",
       "      <td>136.539993</td>\n",
       "      <td>142.919998</td>\n",
       "      <td>140.624741</td>\n",
       "      <td>157611700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-01-26</td>\n",
       "      <td>143.600006</td>\n",
       "      <td>144.300003</td>\n",
       "      <td>141.369995</td>\n",
       "      <td>143.160004</td>\n",
       "      <td>140.860870</td>\n",
       "      <td>98390600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>143.429993</td>\n",
       "      <td>144.300003</td>\n",
       "      <td>140.410004</td>\n",
       "      <td>142.059998</td>\n",
       "      <td>139.778519</td>\n",
       "      <td>140843800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>139.520004</td>\n",
       "      <td>141.990005</td>\n",
       "      <td>136.699997</td>\n",
       "      <td>137.089996</td>\n",
       "      <td>134.888351</td>\n",
       "      <td>142621100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>135.830002</td>\n",
       "      <td>136.740005</td>\n",
       "      <td>130.210007</td>\n",
       "      <td>131.960007</td>\n",
       "      <td>129.840744</td>\n",
       "      <td>177523800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ts        open        high         low       close   adj_close  \\\n",
       "0  2021-01-04  133.520004  133.610001  126.760002  129.410004  127.331688   \n",
       "1  2021-01-05  128.889999  131.740005  128.429993  131.009995  128.905975   \n",
       "2  2021-01-06  127.720001  131.050003  126.379997  126.599998  124.566811   \n",
       "3  2021-01-07  128.360001  131.630005  127.860001  130.919998  128.817429   \n",
       "4  2021-01-08  132.429993  132.630005  130.229996  132.050003  129.929291   \n",
       "5  2021-01-11  129.190002  130.169998  128.500000  128.979996  126.908577   \n",
       "6  2021-01-12  128.500000  129.690002  126.860001  128.800003  126.731491   \n",
       "7  2021-01-13  128.759995  131.449997  128.490005  130.889999  128.787903   \n",
       "8  2021-01-14  130.800003  131.000000  128.759995  128.910004  126.839722   \n",
       "9  2021-01-15  128.779999  130.220001  127.000000  127.139999  125.098160   \n",
       "10 2021-01-19  127.779999  128.710007  126.940002  127.830002  125.777069   \n",
       "11 2021-01-20  128.660004  132.490005  128.550003  132.029999  129.909607   \n",
       "12 2021-01-21  133.800003  139.669998  133.589996  136.869995  134.671875   \n",
       "13 2021-01-22  136.279999  139.850006  135.020004  139.070007  136.836594   \n",
       "14 2021-01-25  143.070007  145.089996  136.539993  142.919998  140.624741   \n",
       "15 2021-01-26  143.600006  144.300003  141.369995  143.160004  140.860870   \n",
       "16 2021-01-27  143.429993  144.300003  140.410004  142.059998  139.778519   \n",
       "17 2021-01-28  139.520004  141.990005  136.699997  137.089996  134.888351   \n",
       "18 2021-01-29  135.830002  136.740005  130.210007  131.960007  129.840744   \n",
       "\n",
       "       volume  \n",
       "0   143301900  \n",
       "1    97664900  \n",
       "2   155088000  \n",
       "3   109578200  \n",
       "4   105158200  \n",
       "5   100384500  \n",
       "6    91951100  \n",
       "7    88636800  \n",
       "8    90221800  \n",
       "9   111598500  \n",
       "10   90757300  \n",
       "11  104319500  \n",
       "12  120150900  \n",
       "13  114459400  \n",
       "14  157611700  \n",
       "15   98390600  \n",
       "16  140843800  \n",
       "17  142621100  \n",
       "18  177523800  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yfin.pipeline(\"AAPL\", \"1D\", \"2021-01-01\", \"2021-01-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "YFinanceSource.validate_data() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m yfin\u001b[39m.\u001b[39;49mpipeline(\u001b[39m\"\u001b[39;49m\u001b[39mAAPL\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m1D\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m2021-01-01\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m2021-01-31\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[16], line 21\u001b[0m, in \u001b[0;36mDataSource.pipeline\u001b[1;34m(self, ticker, interval, start_time, end_time)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfetch_data(ticker, interval, start_time, end_time)\n\u001b[0;32m     20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_data()\n\u001b[1;32m---> 21\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidate_data()\n\u001b[0;32m     22\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\n",
      "\u001b[1;31mTypeError\u001b[0m: YFinanceSource.validate_data() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "yfin.pipeline(\"AAPL\", \"1D\", \"2021-01-01\", \"2021-01-31\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "                  Open        High         Low       Close  Adj Close  Volume\n",
      "Date                                                                         \n",
      "2010-09-09  102.500000  102.500000  101.139999  101.320000  79.068352   26500\n",
      "2010-09-10  101.680000  101.860001  101.300003  101.779999  79.427299    8600\n",
      "2010-09-13  102.959999  103.139999  102.500000  103.059998  80.426216   33750\n",
      "2010-09-14  102.839996  103.480003  102.379997  103.040001  80.410591   59400\n",
      "2010-09-15  102.620003  103.379997  102.400002  103.300003  80.613510    9250\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Create an instance of YFinanceSource, passing the yfinance module as the client\n",
    "yfinance_source = YFinanceSource(client=yf)\n",
    "\n",
    "# Fetch data for Apple Inc. with a daily interval\n",
    "apple_data = yfinance_source.fetch_data(ticker=\"VOO\", interval=\"1d\")\n",
    "\n",
    "# Display the data\n",
    "print(apple_data.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLoader:\n",
    "    def __init__(self, connection_params):\n",
    "        self.connection_params = connection_params\n",
    "\n",
    "    def load_data(self, data):\n",
    "        \"\"\"Load the provided data into the destination.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement this method\")\n",
    "\n",
    "import psycopg2\n",
    "class RedshiftLoader(BaseLoader):\n",
    "    def load_data(self, data):\n",
    "        \"\"\"Load data into Amazon Redshift.\"\"\"\n",
    "        with psycopg2.connect(**self.connection_params) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                # Similar to the SQLLoader but might have Redshift-specific optimizations\n",
    "                pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Redshift successfully!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "with open(\"pwd_redshift.txt\",'r') as f:\n",
    "    pwd= f.read()\n",
    "\n",
    "connection_params = dict(\n",
    "        host='data-engineer-cluster.cyhh5bfevlmn.us-east-1.redshift.amazonaws.com'\n",
    "        , dbname='data-engineer-database'\n",
    "        , user='juanmlacasa_coderhouse'\n",
    "        , password=pwd\n",
    "        , port='5439'\n",
    ")\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        **connection_params\n",
    "    )\n",
    "    print(\"Connected to Redshift successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Unable to connect to Redshift.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extras import execute_values\n",
    "\n",
    "def load_redshift(conn, table_name, dataframe):\n",
    "    dtypes= dataframe.dtypes\n",
    "    cols= list(dtypes.index )\n",
    "    tipos= list(dtypes.values)\n",
    "    type_map = {'int64': 'INT','int32': 'INT','float64': 'FLOAT','object': 'VARCHAR(50)','bool':'BOOLEAN'}\n",
    "    sql_dtypes = [type_map[str(dtype)] for dtype in tipos]\n",
    "    # Define variable SQL data_types\n",
    "    column_defs = [f\"{name} {data_type}\" for name, data_type in zip(cols, sql_dtypes)]\n",
    "    # Combine column definitions into the CREATE TABLE statement\n",
    "    table_schema = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            {', '.join(column_defs)}\n",
    "        );\n",
    "        \"\"\"\n",
    "    # Create table_schema\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(table_schema)\n",
    "    # generate schema values\n",
    "    values = [tuple(x) for x in dataframe.to_numpy()]\n",
    "    # define INSERT INTO statement\n",
    "    insert_sql = f\"INSERT INTO {table_name} ({', '.join(cols)}) VALUES %s\"\n",
    "    # Execute the transaction to insert the data\n",
    "    cur.execute(\"BEGIN\")\n",
    "    execute_values(cur, insert_sql, values)\n",
    "    cur.execute(\"COMMIT\")\n",
    "    print('Proceso terminado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extras import execute_values\n",
    "\n",
    "def load_postgresql(conn, table_name, dataframe):\n",
    "    '''\n",
    "    This function loads data from a Pandas DataFrame into a specified table in a PostgreSQL database.\n",
    "    If records with the same primary key exist, the function updates them with the new values.\n",
    "    '''\n",
    "\n",
    "    # --- Convert DataFrame to List of Tuples ---\n",
    "    # Convert each row of the DataFrame into a tuple and create a list of these tuples\n",
    "    values = [tuple(x) for x in dataframe.to_numpy()]\n",
    "\n",
    "    # --- Format Column Names ---\n",
    "    # Construct a string of column names separated by commas\n",
    "    cols = '\"'+'''\", \"'''.join(dataframe.columns)+'\"'\n",
    "\n",
    "    # --- Prepare SQL Queries ---\n",
    "    # Construct the base INSERT INTO query and append the ON CONFLICT clause\n",
    "    insert_sql = f\"INSERT INTO {schema}.{table_name} ({cols}) VALUES %s\"\n",
    "    on_conflict_sql = f\"\"\"\n",
    "        ON CONFLICT (asset_id, source_id, ts)\n",
    "        DO UPDATE SET\n",
    "            (open, high, low, close, adj_close, volume) = \n",
    "            (EXCLUDED.open, EXCLUDED.high, EXCLUDED.low, EXCLUDED.close, EXCLUDED.adj_close, EXCLUDED.volume)\n",
    "    \"\"\"\n",
    "    insert_sql = insert_sql + on_conflict_sql\n",
    "\n",
    "    # --- Execute Transaction ---\n",
    "    # Execute the query using execute_values for batch insertion\n",
    "    with conn.cursor() as curs:\n",
    "        execute_values(curs, insert_sql, values)\n",
    "        conn.commit()\n",
    "\n",
    "    print('Finished loading data into PostgreSQL.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cargar_en_redshift(conn=conn, table_name='interest_over_time', dataframe=iot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coder-de",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a0f6c032de7be79d5c7f13f397ddb255c643e6cfe5a1086054ff4a4b4b03150"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
